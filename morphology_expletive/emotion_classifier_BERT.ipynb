{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1eHTTiQoh7jj8I313mlxRrT7r5-LYKMLG","authorship_tag":"ABX9TyPJ26uO+hGIWSLG8Mo9bxds"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Build dataset"],"metadata":{"id":"QX136WkkSpkY"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import string\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"jeeB-YSPSsmJ","executionInfo":{"status":"ok","timestamp":1673371292435,"user_tz":360,"elapsed":811,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["dataset_path = \"/content/drive/My Drive/coding/data/unique_tweets_7k.csv\""],"metadata":{"id":"v0wTvo_iS0cM","executionInfo":{"status":"ok","timestamp":1673371294833,"user_tz":360,"elapsed":2,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def load_dataset(path):\n","  data = pd.read_csv(path)\n","  tweet = data.drop_duplicates(subset=[\"text\"])\n","  tweet = tweet[[\"text\",\"sentiment\"]].dropna()\n","  return tweet"],"metadata":{"id":"tTXi758kTJKk","executionInfo":{"status":"ok","timestamp":1673371297228,"user_tz":360,"elapsed":260,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def data_cleaning(df):\n","  def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub(r'', text)\n","  \n","  def remove_html(text):\n","    html = re.compile(r'<.*?>')\n","    return html.sub(r'',text)\n","  \n","  def remove_emoji(text):\n","    emoji_pattern = re.compile(\"[\"\n","                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                                u\"\\U00002702-\\U000027B0\"\n","                                u\"\\U000024C2-\\U0001F251\"\n","                                \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', text)\n","  \n","  def remove_punct(text):\n","        table = str.maketrans('', '', string.punctuation)\n","        return text.translate(table)\n","\n","  def remove_multi_spaces(text):\n","        space = re.compile(' +')\n","        line = re.compile('\\n')\n","        return space.sub(r' ', line.sub(r' ', text))\n","\n","  def remove_hashtags_mentions(text):\n","        hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n","        mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n","        text = hashtags.sub(' hashtag', text)\n","        text = mentions.sub(' entity', text)\n","        return text.strip().lower()\n","\n","  df.text = df.text.apply(lambda x: remove_URL(x))\n","  df.text = df.text.apply(lambda x: remove_html(x))\n","  df.text = df.text.apply(lambda x: remove_emoji(x))\n","  df.text = df.text.apply(lambda x: remove_punct(x))\n","  df.text = df.text.apply(lambda x: remove_multi_spaces(x))\n","  df.text = df.text.apply(lambda x: remove_hashtags_mentions(x))\n","  return df"],"metadata":{"id":"Q7dM6wbkT_wv","executionInfo":{"status":"ok","timestamp":1673371298783,"user_tz":360,"elapsed":197,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def balance_data(df):\n","  df = df.drop(df.query('sentiment == 0').sample(frac=0.7).index)\n","  df = df.drop(df.query('sentiment == 4').sample(frac=0.6).index)\n","  return df"],"metadata":{"id":"2tMBZFmMVRt1","executionInfo":{"status":"ok","timestamp":1673371302350,"user_tz":360,"elapsed":212,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def set_split(df, test_size = 0.2):\n","    train, test = train_test_split(df, test_size = test_size, random_state = 42)\n","    return train, test"],"metadata":{"id":"jees60p4Wrf8","executionInfo":{"status":"ok","timestamp":1673371303853,"user_tz":360,"elapsed":185,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def prepare_train_test_from_file(path):\n","    tweets = load_dataset(path)\n","    tweets = data_cleaning(tweets)\n","    tweets = balance_data(tweets)\n","    return set_split(tweets)"],"metadata":{"id":"XYD-O4daWvK9","executionInfo":{"status":"ok","timestamp":1673371305187,"user_tz":360,"elapsed":1,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["tweets = load_dataset(dataset_path)\n","tweets = data_cleaning(tweets)\n","tweets = balance_data(tweets)\n","train, test = set_split(tweets)"],"metadata":{"id":"-NV3L-4gXIyS","executionInfo":{"status":"ok","timestamp":1673371308894,"user_tz":360,"elapsed":401,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"IXOAml5Cc-eL","executionInfo":{"status":"ok","timestamp":1673371310106,"user_tz":360,"elapsed":271,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}},"outputId":"be69df29-23a9-40c4-d670-fe5f1d158665"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text  sentiment\n","3436  what the hell is going on with mastermind ridi...        2.0\n","1482  hi iâ€™m done with everyoneâ€™s shit today so if a...        2.0\n","2138  life long fear of havin a shit and a spider cr...        3.0\n","1223  fuck this guy get him the fuck outta here i do...        2.0\n","625   ariana grandes new song is absolute shit lmaoðŸ¤£...        0.0"],"text/html":["\n","  <div id=\"df-629e5038-b7a7-465d-ab04-0d516f917f49\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3436</th>\n","      <td>what the hell is going on with mastermind ridi...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1482</th>\n","      <td>hi iâ€™m done with everyoneâ€™s shit today so if a...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2138</th>\n","      <td>life long fear of havin a shit and a spider cr...</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1223</th>\n","      <td>fuck this guy get him the fuck outta here i do...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>625</th>\n","      <td>ariana grandes new song is absolute shit lmaoðŸ¤£...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629e5038-b7a7-465d-ab04-0d516f917f49')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-629e5038-b7a7-465d-ab04-0d516f917f49 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-629e5038-b7a7-465d-ab04-0d516f917f49');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["#Preprocess data as input to BERT"],"metadata":{"id":"4dqe82pgYWui"}},{"cell_type":"code","source":["!pip install bert-for-tf2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_TOJ5PpbhfP","executionInfo":{"status":"ok","timestamp":1673371316800,"user_tz":360,"elapsed":3190,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}},"outputId":"7f7fc888-1bc2-402c-b14e-5491285f821b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.8/dist-packages (0.14.9)\n","Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from bert-for-tf2) (0.8.2)\n","Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.8/dist-packages (from bert-for-tf2) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n"]}]},{"cell_type":"code","source":["!pip install numpy==1.19.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yxufh0JskKT","executionInfo":{"status":"ok","timestamp":1673371328595,"user_tz":360,"elapsed":6307,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}},"outputId":"b198c8e0-c2d0-4db6-f770-702999c4233b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.8/dist-packages (1.19.5)\n"]}]},{"cell_type":"code","source":["!pip install tensorflow==2.2.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZbiwgxKsk6D","executionInfo":{"status":"ok","timestamp":1673371335423,"user_tz":360,"elapsed":4367,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}},"outputId":"308cde10-0fd9-4a4b-a47a-29e9fffe09ff"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow==2.2.0 in /usr/local/lib/python3.8/dist-packages (2.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (2.2.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.14.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (3.19.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (0.38.4)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.4.1)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (2.2.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (2.1.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.19.5)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (2.10.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.51.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (0.3.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.3.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2.0) (1.6.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.25.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.4.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (5.2.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np"],"metadata":{"id":"N4s7luhdsonj","executionInfo":{"status":"ok","timestamp":1673371344262,"user_tz":360,"elapsed":2979,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(np.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RNda3Psst5_","executionInfo":{"status":"ok","timestamp":1673371346191,"user_tz":360,"elapsed":186,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}},"outputId":"fba8f297-bda2-4e14-c774-488fa1f5e814"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["1.19.5\n"]}]},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X67iAfkmswwI","executionInfo":{"status":"ok","timestamp":1673371347935,"user_tz":360,"elapsed":190,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}},"outputId":"91aecd8b-0c49-4d74-d1af-1ebad9d8cf65"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.0\n"]}]},{"cell_type":"code","source":["\n","from tqdm import tqdm\n","from bert.tokenization.bert_tokenization import FullTokenizer\n"],"metadata":{"id":"QjDup-sLYZNh","executionInfo":{"status":"ok","timestamp":1673371350759,"user_tz":360,"elapsed":198,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class SentimentAnalysisData:\n","    DATA_COLUMN = \"text\"\n","    LABEL_COLUMN = \"sentiment\"\n","\n","    def __init__(self, train, test, tokenizer: FullTokenizer, max_seq_len=192):\n","        self.tokenizer = tokenizer\n","        self.max_seq_len = 0\n","\n","        ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n","\n","        print(\"max seq_len\", self.max_seq_len)\n","        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n","        self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n","\n","    def _prepare(self, df):\n","        x, y = [], []\n","\n","        for _, row in tqdm(df.iterrows()):\n","            text, label = row[SentimentAnalysisData.DATA_COLUMN], row[SentimentAnalysisData.LABEL_COLUMN]\n","            tokens = self.tokenizer.tokenize(text)\n","            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n","            token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n","            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n","            x.append(token_ids)\n","            y.append(label)\n","\n","        return np.array(x), np.array(y)\n","\n","    def _pad(self, ids):\n","        x = []\n","        for input_ids in ids:\n","            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n","            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n","            x.append(np.array(input_ids))\n","        return np.array(x)"],"metadata":{"id":"acJm4QX_dKg5","executionInfo":{"status":"ok","timestamp":1673371352686,"user_tz":360,"elapsed":219,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["#Build model"],"metadata":{"id":"9j9pnQ1rXwQv"}},{"cell_type":"code","source":["# import tensorflow as tf\n","from tensorflow import keras \n","import bert\n","from bert import BertModelLayer\n","from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n","import os"],"metadata":{"id":"kanuEEDkXcor","executionInfo":{"status":"ok","timestamp":1673371356622,"user_tz":360,"elapsed":187,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["BERT_MODEL_NAME = \"uncased_L-12_H-768_A-12\"\n","bert_ckpt_dir = \"/content/drive/My Drive/coding/models/uncased_L-12_H-768_A-12\"\n","BERT_CKPT_FILE = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n","bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"],"metadata":{"id":"EKvP2VAtjbgy","executionInfo":{"status":"ok","timestamp":1673371358897,"user_tz":360,"elapsed":193,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def create_model(max_seq_len, num_classes, bert_ckpt_file = BERT_CKPT_FILE):\n","    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n","        bc = StockBertConfig.from_json_string(reader.read())\n","        bert_params = map_stock_config_to_params(bc)\n","        bert_params.adapter_size = None\n","        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n","\n","    input_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n","    bert_output = bert(input_ids)\n","\n","    print(\"bert shape\", bert_output.shape)\n","    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n","    cls_out = keras.layers.Dropout(0.5)(cls_out)\n","    logits = keras.layers.Dense(units=1024, activation=\"tanh\")(cls_out)\n","    logits = keras.layers.Dropout(0.2)(logits)\n","    logits = keras.layers.Dense(units=num_classes, activation=\"softmax\")(logits)\n","\n","    model = keras.Model(inputs=input_ids, outputs=logits)\n","    model.build(input_shape=(None, max_seq_len))\n","\n","    load_stock_weights(bert, bert_ckpt_file)\n","\n","    return model"],"metadata":{"id":"OYcLCLkGj2eJ","executionInfo":{"status":"ok","timestamp":1673371360289,"user_tz":360,"elapsed":221,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["#Train model"],"metadata":{"id":"e1cteqHfj9dD"}},{"cell_type":"code","source":["#import keras\n","# import os\n","from bert.tokenization.bert_tokenization import FullTokenizer"],"metadata":{"id":"0rZOfWJdj9KE","executionInfo":{"status":"ok","timestamp":1673371371344,"user_tz":360,"elapsed":595,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["dirname = \"/content/drive/My Drive/coding/\"\n","DATASET_PATH = os.path.join(dirname, \"data/unique_tweets_7k.csv\")\n","VOCAB_PATH = os.path.join(dirname, \"models/uncased_L-12_H-768_A-12/vocab.txt\")\n","MAX_SEQ_LEN = 40\n","tokenizer = FullTokenizer(vocab_file=VOCAB_PATH)\n","\n","train, test = prepare_train_test_from_file(DATASET_PATH)\n","data = SentimentAnalysisData(train, test, tokenizer, max_seq_len=MAX_SEQ_LEN)\n","model = create_model(data.max_seq_len, 5)\n","model.summary()\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-5),\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",")\n","\n","history = model.fit(\n","    x=data.train_x,\n","    y=data.train_y,\n","    validation_split=0.2,\n","    batch_size=32,\n","    shuffle=True,\n","    epochs=12,\n","    verbose=1\n",")\n","\n","_, test_acc = model.evaluate(data.test_x, data.test_y)\n","_, train_acc = model.evaluate(data.train_x, data.train_y)\n","print(\"Test Accuracy:\" + str(test_acc))"],"metadata":{"id":"yiHAsiIckCr8"},"execution_count":null,"outputs":[]}]}