{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1E07lEy1_7eXazgv223TVTHneqeHg5mvU","authorship_tag":"ABX9TyPuz277eO0IIMpUEoEkud60"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":36,"metadata":{"id":"ADxo-RXZfXYD","executionInfo":{"status":"ok","timestamp":1673286102167,"user_tz":360,"elapsed":117,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"outputs":[],"source":["with open(\"/content/drive/My Drive/coding/data/secret_t.txt\") as f:\n","        secret_ls = f.readlines()\n","        consumer_key = secret_ls[0][:-1]\n","        consumer_secret = secret_ls[1][:-1]\n","        access_token = secret_ls[3][:-1]\n","        access_token_secret = secret_ls[4]\n","        bearer = secret_ls[2][:-1]"]},{"cell_type":"code","source":["import requests\n","import json\n","import csv\n","import string\n","import urllib\n","import re\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","# from hashtag_config import *  \n","# from cleanTweets import *"],"metadata":{"id":"tA9UaUEGy0qm","executionInfo":{"status":"ok","timestamp":1673288975743,"user_tz":360,"elapsed":148,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["sentiments = {0: \"positive\", 1: \"sad\", 2: \"angry\", 3: \"fear\", 4: \"sarcasm\"}"],"metadata":{"id":"DS2bhTM40mY2","executionInfo":{"status":"ok","timestamp":1673289429459,"user_tz":360,"elapsed":137,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["allHashtags = [\n","    set(\n","        [\n","            \"happy\",\n","            \"funny\",\n","            \"greatmood\",\n","            \"superhappy\",\n","            \"atlast\",\n","            \"ecstatic\",\n","            \"thankful\",\n","            \"feelinggood\",\n","            \"love\",\n","            \"loveyou\",\n","            \"joy\",\n","            \"yay\",\n","            \"blessed\",\n","            \"thrilled\",\n","            \"lol\",\n","            \"motivation\",\n","            \"positive\",\n","            \"positivethinking\",\n","            \"excited\",\n","            \"exciting\",\n","            \"fun\",\n","        ]\n","    ),\n","    set(\n","        [\n","            \"sad\",\n","            \"heartbroken\",\n","            \"leftout\",\n","            \"sadness\",\n","            \"depressed\",\n","            \"disappointment\",\n","            \"disappointed\",\n","            \"unhappy\",\n","            \"foreveralone\",\n","        ]\n","    ),\n","    set(\n","        [\n","            \"pissed\",\n","            \"angry\",\n","            \"pissedoff\",\n","            \"furious\",\n","            \"mad\",\n","            \"hateyou\",\n","            \"annoying\",\n","            \"ugh\",\n","            \"anger\",\n","            \"fuming\",\n","            \"heated\",\n","            \"angrytweet\",\n","            \"aggressive\",\n","            \"godie\",\n","            \"pieceofshit\",\n","            \"irritated\",\n","        ]\n","    ),\n","    set(\n","        [\n","            \"afraid\",\n","            \"petrified\",\n","            \"scared\",\n","            \"anxious\",\n","            \"worried\",\n","            \"frightened\",\n","            \"freakedout\",\n","            \"haunted\",\n","        ]\n","    ),\n","    set([\"sarcasm\"]),\n","]"],"metadata":{"id":"yYd44U9kzXmO","executionInfo":{"status":"ok","timestamp":1673289107030,"user_tz":360,"elapsed":123,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["cursewordsCatg = {\n","7: \"General\",\n","0: \"Race\",\n","1: \"Gender-Sexuality\",\n","2: \"Religion\",\n","3: \"Non-Sexual Body Parts\",\n","4: \"Ableist\",\n","5: \"Problem Words\",\n","6: \"Multiple Worded\"}\n","\n","allCurseWords= [\n","  set([\"nigger\",\"n*gger\", \"n*gg*r\", \"chink\",\"niglet\", \"wetback\"]),\n","  set([\"dick\",\"di*k\", \"d*ck\", \"cunt\",\"pussy\",\"pu**y\",\"fag\",\"queer\",\"qu**r\", \"boner\",\"dong\",\"slut\",\"sl*t\",\"dyke\",\"pimp\",\"whore\",\"hoe\",\"bitch\",\"b*tch\", \"bi*ch\",\"cock\",\"tramp\",\"cum\",\"schlong\",\"spunk\",\"skank\",\"motherfucker\",\"tit\",\"gay\",\"mothafucker\",\"screw\",\"blowjob\"]),\n","  set([\"hell\",\"damn\"]),\n","  set([\"ass\", \"queaf\",\"shart\",\"urine\",\"rimming\",\"arse\",\"shat\",\"crap\"]),\n","  set([\"retard\",\"spaz\"]),\n","  set([\"tit\",\"cum\",\"hoe\",\"chink\",\"gay\"]),\n","  set([\"son of a bitch\",\"doggie style\",\"fucked up\"]),\n","  set([\"fuck\",\"fu*k\", \"f*ck\", \"f**k\", \"sh*t\",\"shit\",\"pissed\",\"screw\"]) \n","]\n"],"metadata":{"id":"EU6Cuml-0qxJ","executionInfo":{"status":"ok","timestamp":1673289446166,"user_tz":360,"elapsed":126,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["allEmojis = [\n","    set(\n","        [\n","            \" ;) \",\n","            \":)))\",\n","            \" =) \",\n","            \" :] \",\n","            \" :P \",\n","            \" :-P \",\n","            \" :D \",\n","            \" ;D \",\n","            \":>\",\n","            \":3 \",\n","            \";-)\",\n","            \":-D\",\n","        ]\n","    ),\n","    set([\" :( \", \" :(((\", \" =(((\", \" =( \", \":-(\", \":^(\", \":'(\", \":-<\"]),\n","    set([\" >:S \", \" >:{ \", \" >: \", \" x-@\", \" :@ \", \":-@ \", \" :-/ \", \":/ \"]),\n","    set(\n","        [\n","            \" :-o \",\n","            \" :$ \",\n","            \" :-O \",\n","            \" o_O \",\n","            \" O_o \",\n","            \" :‑O \",\n","            \" :O \",\n","            \" :‑o \",\n","            \" :o \",\n","            \" :-0 \",\n","            \" 8‑0 \",\n","            \">:O\",\n","            \" :-l \",\n","            \" ,:-| \",\n","        ]\n","    ),\n","]"],"metadata":{"id":"fErnp8d84lzE","executionInfo":{"status":"ok","timestamp":1673290475759,"user_tz":360,"elapsed":145,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["kLimitPerCurseWord = 10000\n","kCountPerRequest = 100"],"metadata":{"id":"4S2_F5ewy9Y0","executionInfo":{"status":"ok","timestamp":1673289008840,"user_tz":360,"elapsed":127,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["def getTweets(\n","    bearer, params, curseword, hashtag, writer, sentiment, cursewordCatg\n","):  # deleted headers\n","    print(\"getting Tweets: \", curseword, hashtag, sentiment)\n","    headers = {\"Authorization\": (\"bearer \" + bearer)}\n","    base_url = \"https://api.twitter.com/1.1/search/tweets.json\"\n","    uniqueTweets = set()\n","    while len(uniqueTweets) < kLimitPerCurseWord:\n","        x = requests.get(base_url + params, headers=headers)\n","        res = json.loads(x.text)\n","        if \"statuses\" not in res:\n","            break\n","        for tweet in res[\"statuses\"]:\n","            if tweet[\"full_text\"] not in uniqueTweets:\n","                print(curseword, hashtag, tweet[\"full_text\"])\n","                writer.writerow([tweet[\"full_text\"], sentiment, hashtag, curseword, cursewordCatg])\n","                uniqueTweets.add(tweet[\"full_text\"])\n","        if \"next_results\" not in res[\"search_metadata\"]:\n","            break\n","        params = res[\"search_metadata\"][\"next_results\"]\n","    print(\"#\", hashtag, curseword, \"got\", len(uniqueTweets), \"tweets\")"],"metadata":{"id":"lPPW_IX9zAsA","executionInfo":{"status":"ok","timestamp":1673289034442,"user_tz":360,"elapsed":127,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["def runTweetsScraper():\n","    with open(\"/content/drive/My Drive/coding/data/well_formatted.csv\", \"a\", newline=\"\") as file:\n","        writer = csv.writer(file)\n","        for sentiment, hashtagSet in enumerate(allHashtags):\n","            for hashtag in hashtagSet:\n","                for cursewordCatg, cursewordSet in enumerate(allCurseWords):\n","                    for curseword in cursewordSet:\n","                        try:\n","                            getTweets(\n","                                bearer,\n","                                \"?q=%23\"\n","                                + hashtag\n","                                + \"%20\"\n","                                + curseword\n","                                + \"&lang=en&tweet_mode=extended&count=\"\n","                                + str(kCountPerRequest),\n","                                curseword,\n","                                hashtag,\n","                                writer,\n","                                sentiment,\n","                                cursewordCatg,\n","                            )\n","                        except Exception as e:\n","                            print(\"An exception occurred at\", hashtag, curseword)\n","                            print(e)"],"metadata":{"id":"7IwclaLyzJyT","executionInfo":{"status":"ok","timestamp":1673289506621,"user_tz":360,"elapsed":118,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["runTweetsScraper()"],"metadata":{"id":"GIrorXrX0uyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stopwords = set([\"RT\"])\n","\n","def remove_stopwords(text):\n","    for stopword in stopwords:\n","       text = text.replace(stopword, '') \n","    text = text.replace('\"', '') \n","    return text\n","def remove_URL(text):\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url.sub(\"URL\",text)\n","def to_lower(text):\n","    return text.lower()\n","def remove_html(text):\n","    html=re.compile(r'<.*?>')\n","    return html.sub(r'',text)\n","def remove_repeatCharacters(text):\n","   return re.sub(r'(.)\\1{2,}',r'\\1', text)\n","def remove_hashtags(text):\n","  array = text.split(' ')\n","  isPreviousHashtag = False\n","  previousWord = \"\"\n","  isLast = True\n","  for word in array[::-1]:\n","    if(len(word)<1 or word == 'URL' or word == 'USERID'):\n","      continue\n","\n","    if(word[0] == '#'):\n","      \n","      if(isPreviousHashtag):\n","        text = text.replace(word, \"\")\n","        text = text.replace(previousWord, \"\")\n","      if(isLast):\n","        text = text.replace(word, \"\")\n","        isLast = False\n","      previousWord = word\n","      isPreviousHashtag = True\n","      \n","    else:\n","      isPreviousHashtag = False\n","  return text\n","\n","def tweetIsNotTooShort(text):\n","  return len(text.split(' '))>6\n","\n","def tweetContainsCurseWord(text):\n","  text = text.split(' ')\n","  for word in text:\n","    for i in range(len(allCurseWords)):\n","      for curseword in allCurseWords[i]:\n","        if(curseword in word):\n","          return True\n","  return False\n","\n","def keepNonAmbigousTweets(text):\n","  wordSentiment = -1\n","  text = text.split(' ')\n","  for word in text:\n","    #word could be #hashtag, :), or hello\n","    for i in range(len(allEmojis)):\n","      if( word in allEmojis[i]):\n","        if(wordSentiment==-1):\n","          wordSentiment = i\n","        elif(wordSentiment!=i):\n","          return False\n","    for i in range(len(allHashtags)):\n","      if( word[1:] in allHashtags[i]):\n","        if(wordSentiment==-1):\n","          wordSentiment = i\n","        elif(wordSentiment!=i):\n","          return False\n","  if (wordSentiment == -1):\n","    return False\n","  return True\n","          \n","def remove_emoji(text):\n","    emoji_pattern = re.compile(\"[\"\n","                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                           u\"\\U00002702-\\U000027B0\"\n","                           u\"\\U000024C2-\\U0001F251\"\n","                           \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', text)\n","def remove_punct(text):\n","    table=str.maketrans('','',string.punctuation)\n","    return text.translate(table)\n","def remove_userids(text):\n","    text = text.split(' ')\n","    res = \"\"\n","    for piece in text:\n","      if len(piece)>=1 and piece[0] != '@':\n","        res+= piece + \" \"\n","      else:\n","        res+= \" USERID \"\n","   \n","    return res\n","\n","\n","def findUniqueTweets(infile, outfile):\n","    twitter = pd.read_csv(infile,\n","                          names=['text', 'sentiment', 'hashtag','curseword','cursewordCatg'])\n","    print(\"all: \", twitter.shape)\n","    #twitter = twitter[twitter[\"curseword\"] != \"a**\"]\n","    twitter.drop_duplicates(subset=[\"text\"], inplace=True)\n","    print(\"after dropping duplicates: \", twitter.shape)\n","\n","    # step 0: convert everything to lower case, remove stop words\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: to_lower(x))\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_stopwords(x))\n","\n","    # step 1: replace @USERID with USERID\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_userids(x))\n","    # step 2: replace links with URL\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_URL(x))\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_html(x))\n","    # step 3: replace \"happyyyyy\" with happy, \":))))\" with \":)\"\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_repeatCharacters(x))\n","    # step 4: remove tweets containing 0, or more than one sentiment labels eg. #happy and #sad,  :) and :(, #happy and :(\n","    twitter = twitter[twitter[\"text\"].apply(keepNonAmbigousTweets) == True]\n","    print(\"after dropping ambigious tweets: \", twitter.shape)\n","\n","    # step 5: remove hashtags from the end of the text\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_hashtags(x))\n","\n","    # step 6: remove tweets that don't contain curseword\n","    twitter = twitter[twitter[\"text\"].apply(tweetContainsCurseWord) == True]\n","    print(\"after dropping tweets without cursewords: \", twitter.shape)\n","\n","    # step 7: remove emojis, punctuation\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_emoji(x))\n","    twitter[\"text\"] = twitter[\"text\"].apply(lambda x: remove_punct(x))\n","\n","    # step 8: remove tweets that are less than 6 words long\n","    twitter = twitter[twitter[\"text\"].apply(tweetIsNotTooShort) == True]\n","    print(\"after dropping short tweets: \", twitter.shape)\n","\n","    twitter2 = twitter.sort_values([\"text\"])\n","    twitter2.drop_duplicates(subset=[\"text\"], inplace=True)\n","    print(\"after dropping duplicates: \", twitter2.shape)\n","\n","    twitter2.to_csv(outfile, index=False)\n","    print(\"unique: \", twitter2.shape)"],"metadata":{"id":"BRgRLIMK3sZl","executionInfo":{"status":"ok","timestamp":1673290779596,"user_tz":360,"elapsed":139,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["infile = \"/content/drive/My Drive/coding/data/well_formatted.csv\"\n","outfile = \"/content/drive/My Drive/coding/data/unique_tweets.csv\"\n","findUniqueTweets(infile, outfile)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6ZaUybl4ufq","executionInfo":{"status":"ok","timestamp":1673290783699,"user_tz":360,"elapsed":255,"user":{"displayName":"Jinghua OU","userId":"09327599624740105790"}},"outputId":"c295a911-5aa5-4ab7-af24-0b4f831aaac5"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["all:  (606, 5)\n","after dropping duplicates:  (528, 5)\n","after dropping ambigious tweets:  (384, 5)\n","after dropping tweets without cursewords:  (331, 5)\n","after dropping short tweets:  (331, 5)\n","after dropping duplicates:  (327, 5)\n","unique:  (327, 5)\n"]}]}]}