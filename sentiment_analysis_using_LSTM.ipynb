{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "122_tLuNHbqO2LP7H2Ay07loTT153EEWL",
      "authorship_tag": "ABX9TyN9v4FSy/t/qh6h+nH6klVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhou27/NLP_with_Python/blob/main/sentiment_analysis_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "SGfiTrpCzaWK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read IMDB movies reivew dataset\n",
        "with open('/content/drive/My Drive/coding/IMDB_Dataset.csv', 'r') as f:\n",
        " reviews = f.read()\n",
        "\n",
        "with open('/content/drive/My Drive/coding/labels.csv', 'r') as f:\n",
        " labels = f.read()\n",
        "\n",
        "print(reviews[:50])\n",
        "print()\n",
        "print(labels[:26])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INTWcRpnp3vm",
        "outputId": "5e085f7d-e763-48a5-b33c-410c20d211ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review,sentiment\n",
            "\"One of the other reviewers has m\n",
            "\n",
            "positive\n",
            "positive\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing - convert to lower case"
      ],
      "metadata": {
        "id": "XnsOVYy7rAeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = reviews.lower()"
      ],
      "metadata": {
        "id": "BBdot5NYrGLe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Precessing - remove punctuation"
      ],
      "metadata": {
        "id": "1e_y8FYerLCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(punctuation)\n",
        "\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S78emturOwF",
        "outputId": "ab38e944-0ca9-4af6-d88b-db87fabb6884"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing - create list of reviews\n",
        "all the words are in one huge string. Now separate out individual reviews and store them as individual list elements. Like, [review1, review2, review3.....reviewn]"
      ],
      "metadata": {
        "id": "X2uPMejtrgnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_split = all_text.split('\\n')\n",
        "print('Number of reviews:',len(reviews_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hUD6JsdrpBy",
        "outputId": "0cb37a43-a3ef-4e97-8527-5374eb0d7ff6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews: 50002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenize - create vocab to Int mapping dictionary\n",
        "create an index mapping dictionary in a way that frequently occurring words are assigned lower indices. "
      ],
      "metadata": {
        "id": "e13RHGtis3Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "#create a list of words\n",
        "words = all_text.split()\n",
        "#count all the unique words using Counter\n",
        "count_words = Counter(words)\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)"
      ],
      "metadata": {
        "id": "d1M_oxeZtKjP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted_words[:10])\n",
        "word_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "#let's take a look at the first 3 most frequent words\n",
        "for idx, (k, v) in enumerate(word_to_int.items()):\n",
        "  if idx == 3: break\n",
        "  print((k, v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QwGOW6buJ70",
        "outputId": "0f32cd98-aed8-49e1-ce45-1af14cf2d07c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 663814), ('and', 320662), ('a', 320447), ('of', 288352), ('to', 266729), ('is', 210003), ('in', 184812), ('i', 152081), ('it', 151021), ('this', 148990)]\n",
            "('the', 1)\n",
            "('and', 2)\n",
            "('a', 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenize - Encode the words\n",
        "so far we have 1) list of reviews and 2) index mapping dictionary. Now need to create an encoding of reviews."
      ],
      "metadata": {
        "id": "a_mlRvokxDOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_int =[]\n",
        "for review in reviews_split:\n",
        "  r = [word_to_int[w] for w in review.split()]\n",
        "  reviews_int.append(r)\n",
        "reviews_int = reviews_int[1:] \n",
        "print(reviews_int[0:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHp7Fjp6xW7g",
        "outputId": "2e5c138e-021e-4428-8db7-e3f110d60fcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[28, 4, 1, 77, 1938, 44, 1064, 11, 99, 145, 40, 480, 3358, 397, 456, 26, 3200, 34, 23, 207, 14, 10, 6, 600, 48, 593, 15, 2127, 12, 1, 87, 147, 11, 3256, 69, 42, 3358, 13, 29, 5602, 2, 15550, 134, 4, 587, 59, 280, 7, 207, 35, 1, 669, 138, 1698, 69, 10, 6, 21, 3, 118, 16, 1, 8363, 5836, 39, 11949, 10, 118, 2491, 55, 6069, 15, 5805, 5, 1478, 380, 39, 587, 29, 6, 3400, 7, 1, 362, 337, 4, 1, 23896, 12, 9, 6, 465, 3358, 14, 11, 6, 1, 11601, 335, 5, 1, 16177, 6895, 2527, 1062, 64059, 9, 2624, 1370, 20, 25808, 535, 33, 4715, 2528, 4, 1, 1205, 112, 31, 1, 7391, 25, 2996, 13566, 2, 410, 64060, 37, 17736, 6, 21, 318, 20, 1, 5123, 3802, 535, 6, 343, 5, 85675, 8517, 42250, 15551, 5193, 7917, 2452, 2, 18636, 64061, 327, 9307, 7499, 13790, 2, 8757, 35767, 23, 109, 225, 5430, 12, 8, 57, 128, 1, 268, 1302, 4, 1, 118, 6, 665, 5, 1, 187, 11, 9, 262, 112, 77, 257, 547, 3033, 818, 177, 1273, 4343, 16, 2481, 1107, 818, 1428, 818, 85676, 146, 1009, 181, 1, 87, 397, 8, 119, 201, 3256, 69, 14, 37, 1570, 9, 13, 2214, 8, 393, 128, 8, 13, 1562, 16, 9, 18, 14, 8, 274, 52, 8, 1456, 3, 1269, 16, 3358, 2, 183, 10340, 5, 1, 318, 2117, 4, 2092, 587, 21, 40, 587, 18, 8126, 7169, 5000, 14316, 26, 2960, 45, 16, 3, 33342, 7057, 14316, 493, 20, 621, 2, 75, 243, 15, 9, 73, 9972, 747, 816, 7057, 105, 656, 79, 1205, 20882, 665, 5, 62, 549, 4, 934, 2001, 39, 1205, 583, 145, 3358, 22, 196, 411, 3781, 15, 48, 6, 3285, 85677, 43, 22, 68, 75, 7, 1211, 15, 122, 4010, 42251], [3, 383, 114, 356, 12, 12, 1, 1361, 3000, 6, 51, 18637, 51, 85678, 1633, 2, 387, 3, 13567, 2, 514, 28191, 282, 4, 1886, 5, 1, 419, 408, 12, 12, 1, 150, 23, 544, 73, 2264, 491, 4608, 21, 60, 44, 183, 31, 1, 85679, 18, 27, 44, 31, 1, 2218, 185, 3286, 100, 22, 68, 345, 64, 1, 14043, 799, 10210, 32, 1, 1800, 5, 1663, 7550, 6842, 21, 60, 6, 9, 73, 265, 1, 145, 18, 9, 6, 3, 42252, 426, 2, 2366, 408, 3, 4364, 356, 42, 28, 4, 1, 80, 3209, 4, 215, 2, 24, 120, 12, 12, 1, 1886, 61, 260, 343, 15, 1, 114, 176, 1, 1072, 4, 1, 2975, 59, 240, 70, 337, 1, 2135, 1030, 3148, 1239, 1143, 90, 5124, 9, 286, 20, 249, 1795, 2, 249, 4626, 565, 15, 1, 134, 3601, 20235, 2, 28192, 2, 1, 714, 565, 4, 62, 1096, 15, 85680, 64062, 29673, 165, 2248, 23, 1903, 73, 11017], [8, 193, 10, 13, 3, 383, 98, 5, 1108, 63, 20, 3, 100, 910, 1475, 2482, 1186, 7, 1, 951, 16936, 770, 2, 145, 3, 4011, 215, 1, 113, 6, 4038, 18, 1, 406, 6, 1863, 2, 1, 101, 23, 1466, 54, 1, 73, 6660, 6718, 1539, 497, 133, 46, 196, 26, 738, 50, 34, 926, 10, 6, 21, 1033, 221, 284, 3138, 5275, 8, 193, 9, 13, 3039, 11, 2941, 2044, 6, 125, 1374, 7, 1151, 4, 1, 429, 104, 4, 169, 25, 2322, 5, 6197, 12, 10, 13, 1, 86, 450, 1387, 30, 28, 4, 20236, 1309, 7, 151, 3033, 8, 128, 3, 2137, 133, 195, 109, 74, 1504, 15, 9308, 42253, 7, 10, 58, 1264, 5, 1234, 185, 41, 1237, 1393, 2, 5025, 207, 79, 3, 862, 18, 5125, 182, 11151, 12, 10, 196, 21, 26, 1, 7795, 5243, 4, 24, 648, 18, 9, 13, 33343, 70, 2293, 2868, 25809, 2, 52, 218, 70, 2633, 3, 80, 215, 5, 138, 64, 15, 19662]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenize - Encode the labels\n",
        "label 'positive' as 1 and 'negative' as 0"
      ],
      "metadata": {
        "id": "lmejClK2yo01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_labels = [1 if label == 'positive' else 0 for label in labels.split()]\n",
        "encoded_labels = np.array(encoded_labels)\n",
        "print(encoded_labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY2N3c5pyoev",
        "outputId": "96be2210-b1a0-4173-b2a6-1667ba745d3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 1 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analyze reviews length"
      ],
      "metadata": {
        "id": "5mz2vZUFztd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_len = [len(x) for x in reviews_int]\n",
        "pd.Series(reviews_len).hist()\n",
        "plt.show()\n",
        "pd.Series(reviews_len).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "MnlH_kjKzwmg",
        "outputId": "1d26b086-7fd2-4488-a875-c2e03356b26e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    50001.000000\n",
              "mean       230.296154\n",
              "std        170.666036\n",
              "min          0.000000\n",
              "25%        126.000000\n",
              "50%        172.000000\n",
              "75%        280.000000\n",
              "max       2470.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_int = [ reviews_int[i] for i, l in enumerate(reviews_len) if l>0 ]\n",
        "encoded_labels = [ encoded_labels[i] for i, l in enumerate(reviews_len) if l> 0 ]\n"
      ],
      "metadata": {
        "id": "gnXt0Xjx2BTX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Padding/Truncating the data"
      ],
      "metadata": {
        "id": "tzDrRpma2QWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(reviews_int, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
        "    \n",
        "    for i, review in enumerate(reviews_int):\n",
        "        review_len = len(review)\n",
        "        \n",
        "        if review_len <= seq_length:\n",
        "            zeroes = list(np.zeros(seq_length-review_len))\n",
        "            new = zeroes+review\n",
        "        elif review_len > seq_length:\n",
        "            new = review[0:seq_length]\n",
        "        \n",
        "        features[i,:] = np.array(new)\n",
        "    \n",
        "    return features\n",
        "seq_length=200\n",
        "features = pad_features(reviews_int, seq_length)\n",
        "len_feat = len(features)\n",
        "print(len_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2ITI5EI2NvE",
        "outputId": "b8645978-2454-49de-cec5-db8a755806e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training, Validating, testing dataset Split"
      ],
      "metadata": {
        "id": "OZvygBHA2kHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_frac = 0.8\n",
        "train_x = features[0:int(split_frac*len_feat)]\n",
        "train_y = encoded_labels[0:int(split_frac*len_feat)]\n",
        "remaining_x = features[int(split_frac*len_feat):]\n",
        "remaining_y = encoded_labels[int(split_frac*len_feat):]\n",
        "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
        "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
        "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
        "test_y = remaining_y[int(len(remaining_y)*0.5):]"
      ],
      "metadata": {
        "id": "RQC9fCY72qU3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataloaders and Batching"
      ],
      "metadata": {
        "id": "O6L62GGe5X7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(np.asarray(train_x)), torch.from_numpy(np.asarray(train_y)))\n",
        "valid_data = TensorDataset(torch.from_numpy(np.asarray(valid_x)), torch.from_numpy(np.asarray(valid_y)))\n",
        "test_data = TensorDataset(torch.from_numpy(np.asarray(test_x)), torch.from_numpy(np.asarray(test_y)))\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "9m9nTSmy5ca_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrPuY-ht2dXV",
        "outputId": "b1f7086d-b94b-4681-81fe-5ac40d46a732"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[     1,  14199,    827,  ...,   6886,    353,     10],\n",
            "        [     0,      0,      0,  ...,     10, 125317,  76489],\n",
            "        [   131,     43,    246,  ...,    355,    142,     23],\n",
            "        ...,\n",
            "        [     0,      0,      0,  ...,    122,    198,  33589],\n",
            "        [     1,   1242,   1803,  ...,      6,    125,     28],\n",
            "        [   796,     19,   1437,  ...,     11,     22,     23]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
            "        0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
            "        1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the LSTM Network Architecture\n",
        "1. Embedding Layer: that converts our word tokens (integers) into embedding of specific size\n",
        "2. LSTM Layer: defined by hidden state dims and number of layers\n",
        "Fully Connected Layer: that maps output of LSTM layer to a desired output size\n",
        "3. Sigmoid Activation Layer: that turns all output values in a value between 0 and 1\n",
        "4. Output: Sigmoid output from the last timestep is considered as the final output of this network"
      ],
      "metadata": {
        "id": "Pv4aYSZy5vEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "metadata": {
        "id": "smcCFdNK52mW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the Network"
      ],
      "metadata": {
        "id": "7dV9QfI-6FHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(word_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEh8Lq4o6HZr",
        "outputId": "93fd0880-6e7b-41db-f2d8-4f87f73b8260"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(191959, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgAZO2nf_fM5",
        "outputId": "47029eda-3f4f-44e2-df1b-278996dc1169"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training loop"
      ],
      "metadata": {
        "id": "LyRVVF0G7zjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "# training params\n",
        "\n",
        "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        #inputs = inputs.type(torch.LongTensor)\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                #inputs = inputs.type(torch.LongTensor)\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5SpIvi71mW",
        "outputId": "786a23e1-6883-4839-e937-41569bfb4925"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/4... Step: 100... Loss: 0.577756... Val Loss: 0.652818\n",
            "Epoch: 1/4... Step: 200... Loss: 0.527442... Val Loss: 0.581401\n",
            "Epoch: 1/4... Step: 300... Loss: 0.377034... Val Loss: 0.476955\n",
            "Epoch: 1/4... Step: 400... Loss: 0.515478... Val Loss: 0.501427\n",
            "Epoch: 1/4... Step: 500... Loss: 0.417854... Val Loss: 0.456940\n",
            "Epoch: 1/4... Step: 600... Loss: 0.450819... Val Loss: 0.524028\n",
            "Epoch: 1/4... Step: 700... Loss: 0.551558... Val Loss: 0.428641\n",
            "Epoch: 1/4... Step: 800... Loss: 0.400869... Val Loss: 0.439015\n",
            "Epoch: 2/4... Step: 900... Loss: 0.360243... Val Loss: 0.378163\n",
            "Epoch: 2/4... Step: 1000... Loss: 0.382395... Val Loss: 0.390793\n",
            "Epoch: 2/4... Step: 1100... Loss: 0.223113... Val Loss: 0.386322\n",
            "Epoch: 2/4... Step: 1200... Loss: 0.275143... Val Loss: 0.438605\n",
            "Epoch: 2/4... Step: 1300... Loss: 0.204208... Val Loss: 0.352017\n",
            "Epoch: 2/4... Step: 1400... Loss: 0.349205... Val Loss: 0.352346\n",
            "Epoch: 2/4... Step: 1500... Loss: 0.354780... Val Loss: 0.348575\n",
            "Epoch: 2/4... Step: 1600... Loss: 0.387398... Val Loss: 0.316347\n",
            "Epoch: 3/4... Step: 1700... Loss: 0.140215... Val Loss: 0.377678\n",
            "Epoch: 3/4... Step: 1800... Loss: 0.282730... Val Loss: 0.354571\n",
            "Epoch: 3/4... Step: 1900... Loss: 0.125210... Val Loss: 0.366868\n",
            "Epoch: 3/4... Step: 2000... Loss: 0.095177... Val Loss: 0.352279\n",
            "Epoch: 3/4... Step: 2100... Loss: 0.154066... Val Loss: 0.334517\n",
            "Epoch: 3/4... Step: 2200... Loss: 0.174049... Val Loss: 0.329337\n",
            "Epoch: 3/4... Step: 2300... Loss: 0.135092... Val Loss: 0.382889\n",
            "Epoch: 3/4... Step: 2400... Loss: 0.132799... Val Loss: 0.374881\n",
            "Epoch: 4/4... Step: 2500... Loss: 0.101432... Val Loss: 0.392065\n",
            "Epoch: 4/4... Step: 2600... Loss: 0.033557... Val Loss: 0.394657\n",
            "Epoch: 4/4... Step: 2700... Loss: 0.068427... Val Loss: 0.381632\n",
            "Epoch: 4/4... Step: 2800... Loss: 0.093961... Val Loss: 0.388257\n",
            "Epoch: 4/4... Step: 2900... Loss: 0.045905... Val Loss: 0.389086\n",
            "Epoch: 4/4... Step: 3000... Loss: 0.018910... Val Loss: 0.394134\n",
            "Epoch: 4/4... Step: 3100... Loss: 0.187412... Val Loss: 0.398888\n",
            "Epoch: 4/4... Step: 3200... Loss: 0.073936... Val Loss: 0.359362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "Hsbu3bg_8Fai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    #inputs = inputs.type(torch.LongTensor)\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBJt7RtK8G3T",
        "outputId": "d3dd0906-f328-4fac-bbb3-8d4060e15d80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.349\n",
            "Test accuracy: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now the LSTM is trained on the data, we can test it on User-generated Data"
      ],
      "metadata": {
        "id": "OoOt-WcHBtLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_review = 'This movie had the best acting and the dialogue was so good. I loved it.'\n"
      ],
      "metadata": {
        "id": "EtO36o3YCJZT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([word_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "\n",
        "# test code and generate tokenized review\n",
        "test_ints = tokenize_review(test_review)\n",
        "print(test_ints)\n",
        "\n",
        "\n",
        "# test sequence padding\n",
        "seq_length=200\n",
        "features = pad_features(test_ints, seq_length)\n",
        "\n",
        "print(features)\n",
        "\n",
        "\n",
        "# test conversion to tensor and pass into your model\n",
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size())\n",
        "\n",
        "\n",
        "def predict(net, test_review, sequence_length=200):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # tokenize review\n",
        "    test_ints = tokenize_review(test_review)\n",
        "    \n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "    \n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    # printing output value, before rounding\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "    \n",
        "    # print custom response\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdLAwXqWB0L2",
        "outputId": "7f2f3ad4-37e0-45e8-bd63-8876ccfdc193"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10, 17, 66, 1, 116, 111, 2, 1, 406, 13, 37, 49, 8, 414, 9]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0  10  17  66   1 116 111   2   1 406  13  37  49   8\n",
            "  414   9]]\n",
            "torch.Size([1, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(net, test_review, seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg1ExqiMCohL",
        "outputId": "c4ce6f38-f6b2-48a8-8710-b9300cc80d1e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction value, pre-rounding: 0.993761\n",
            "Positive review detected!\n"
          ]
        }
      ]
    }
  ]
}