{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1idfDjG9YbOK5N4wtJ9vM6z2vgArMjjgh",
      "authorship_tag": "ABX9TyM8OWPQXfmS/7BuEuzhEZYp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK0CLELfJrzS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "imdb_reviews = pd.read_csv('/content/drive/My Drive/coding/IMDB_Dataset.csv')\n",
        "twitter_tweets=pd.read_csv('/content/drive/My Drive/coding/train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lowercasing"
      ],
      "metadata": {
        "id": "uJULErfFLBUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_lowercase(column):\n",
        "  column = column.str.lower()\n",
        "  return column"
      ],
      "metadata": {
        "id": "bVkF5FDqNDhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove HTML tags"
      ],
      "metadata": {
        "id": "Zf_qvLUxN9BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_html_tags(text):\n",
        "  re_html = re.compile('<.*?>')\n",
        "  return re_html.sub(r'', text)"
      ],
      "metadata": {
        "id": "PbGWn2m9OEUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove URLs"
      ],
      "metadata": {
        "id": "OUFnaKNXQonc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(text):\n",
        "  re_url = re.compile('http?://\\S+|www\\.\\S+')\n",
        "  return re_url.sub('', text)"
      ],
      "metadata": {
        "id": "ukIHbyChQrNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove punctuations"
      ],
      "metadata": {
        "id": "MZi2lx7mROj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "exclude = string.punctuation\n",
        "\n",
        "text ='hello!'\n",
        "\n",
        "all_text = ''.join([c for c in text if c not in exclude])\n",
        "#another way to do this cleaning\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))"
      ],
      "metadata": {
        "id": "Qi7CLsJoRNYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5345bdc4-13e0-4c09-b381-22ed2169e175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chat word treatment"
      ],
      "metadata": {
        "id": "61iEL-lWR91X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words={\n",
        "    'FYI': 'for your information',\n",
        "    'LOL':'laugh out loud',\n",
        "    'AFK': 'away from keyboard'\n",
        "}\n",
        "\n",
        "def chat_words_conv(text):\n",
        "  new_text =[]\n",
        "  for word in text.split():\n",
        "    if word.upper() in chat_words:\n",
        "      new_text.append(chat_words[word.upper()])\n",
        "    else:\n",
        "      new_text.append(word)\n",
        "  return ''.join(new_text)"
      ],
      "metadata": {
        "id": "EnuP-JAtSDtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spelling correction"
      ],
      "metadata": {
        "id": "SbUIR-OaTgOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Textblob\n",
        "textblob_ = Textblob(text)"
      ],
      "metadata": {
        "id": "j_u_kk8QTiqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove stop words"
      ],
      "metadata": {
        "id": "upXjhHF9UKSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords_english = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  new_text = []\n",
        "  for word in text.split():\n",
        "    if word in stopwords_english:\n",
        "        continue\n",
        "    else:\n",
        "      new_text.append(word)\n",
        "  return ''.join(new_text)"
      ],
      "metadata": {
        "id": "iW9O3P4dUMbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Handling emojis"
      ],
      "metadata": {
        "id": "N97WRzowU8Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "text = 'He is suffering from fever ðŸ¤’'\n",
        "print(emoji.demojize(text))"
      ],
      "metadata": {
        "id": "mEoJXBRWU-u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "g_qSN9miWaUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "sent_1 = 'Life is a matter of choices and every choice makes you!'\n",
        "print(word_tokenize(sent_1))"
      ],
      "metadata": {
        "id": "h1Pw1igsWZ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "sent_2 = 'A 5km bike ride costs around $10 in New York!'\n",
        "doc = nlp(sent_2)\n",
        "for token in doc:\n",
        "    print(token, end= ', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83j-GjKQXBW5",
        "outputId": "18835f56-a365-4685-e91c-c58d2e67e00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A, 5, km, bike, ride, costs, around, $, 10, in, New, York, !, "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#stemming"
      ],
      "metadata": {
        "id": "Exltu92FXYhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "def perform_stemming(text):\n",
        "  new_text = [ps.stem(word) for word in text.split()]\n",
        "  return ''.join(new_text)"
      ],
      "metadata": {
        "id": "jozPo8csXaVT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}